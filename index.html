<!DOCTYPE HTML>
<html lang="en"><head>
  
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-XER1L7W1YQ"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-XER1L7W1YQ');
  </script>

  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Luca Masserano</title>
  
  <meta name="author" content="Luca Masserano">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Luca Masserano</name>
              </p>
              <p>Hello! I am Luca, a PhD student in the Joint PhD Program in Statistics and Machine Learning at Carnegie Mellon University, where I am fortunate to be advised by 
                <a href="https://www.stat.cmu.edu/~annlee/">Ann B. Lee</a> and <a href="http://www.cs.cmu.edu/~bapoczos/">Barnab√°s P√≥czos</a>. 
              </p>
              <p>
                I am broadly interested in statistics and machine learning, with a current focus on robust uncertainty quantification in likelihood-free settings: I develop 
                methods with sound statistical guarantees leveraging modern machine learning (e.g., deep generative models) to quantify the uncertainty on parameters that govern complex physical processes. 
              </p>
              <p>
                I have also been working on probabilistic forecasting and optimization during various internships, and I am keen on learning more about these topics too. At CMU, I am part of the Statistical Methods for the Physical Sciences (<a href="https://www.stat.cmu.edu/stamps/">STAMPS</a>) group. My research has been 
                supported by the National Science Foundation (<a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2020295&HistoricalAwards=false">grant #2020295</a>) and by the CMU 2024 Presidential Fellowship for the Statistics Department.
              </p>
              <p>
                I am spending this summer as a Machine Learning Scientist Intern @ AWS AI Labs in Santa Clara (CA), where I will be exploring different properties of Foundation Models for time series forecasting.
              </p>
              <p>
                Before joining CMU, I obtained an M.Sc. in Data Science (Statistics) at Bocconi University in Milan (Italy), where I was advised by <a href="https://mypage.unibocconi.eu/igorpruenster/">Igor Pruenster</a> and 
                <a href="https://mypage.unibocconi.eu/antoniolijoi/">Antonio Lijoi</a>.                
              </p>
              <p style="text-align:center">
                <a href="mailto:lmassera@andrew.cmu.edu">Email</a> &nbsp/&nbsp
                <a href="data/cv_lucamasserano.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=hJpzTpoAAAAJ&hl=en&authuser=1">Scholar</a> &nbsp/&nbsp
                Github: <a href="https://github.com/lucamasserano">Personal</a> - <a href="https://github.com/lee-group-cmu">Group</a> &nbsp/&nbsp 
                <a href="https://www.linkedin.com/in/luca-masserano/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/headshot_new_circle.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/headshot_new_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        
        <ul>
          <li>
            <b>07/2024</b> - Looking forward to attend ICML 2024 in Vienna, where I will be presenting our work on <a href="https://arxiv.org/abs/2402.05330">Classification under Nuisance Parameters and Generalized Label Shift in Likelihood-Free Inference </a>

          </li>
          <br>
          <li>
            <b>05/2024</b> - Excited to start a summer internship @ AWS AI Labs in Santa Clara (CA), where I will be working on different aspects of Foundation Models for time series forecasting.
          </li>
          <br>
          <li>
            <b>02/2024</b> - I will be at the SIAM Conference on Uncertainty Quantification in Trieste, Italy!
          </li>
          <!--
          <br>
          <li>
            <b>06/2023</b> - This summer I will again join the wonderful ML Forecasting team in Berlin (Germany), working on integrating combinatorial solvers into differentiable pipelines!
          </li>
          <br>
          <li>
            <b>01/2023</b> - The paper <em>‚ÄúSimulation-Based Inference with WALDO: Confidence Regions by Leveraging Prediction Algorithms and 
              Posterior Estimators for Inverse Problems‚Äù</em>, has been selected as a winner of the 2023 ASA Physical and Engineering Sciences Student Paper Competition!
          </li>
          <br>
          <li>
            <b>01/2023</b> - Excited to announce that the paper <em>‚ÄúSimulation-Based Inference with WALDO: Confidence Regions by Leveraging Prediction Algorithms or 
              Posterior Estimators for Inverse Problems‚Äù</em>, has been accepted for presentation at AISTATS 2023. Thanks to all my collaborators for the hard work!
          </li>
          <br>
          <li>
            <b>12/2022</b> - Looking forward to present two papers at NeurIPS 2022: 
            <ul>
              <li>
                <em>‚ÄúAdaptive Sampling for Probabilistic Forecasting under Distribution Shift‚Äù</em> at the ‚ÄúDistribution Shifts: Connecting Methods and Applications‚Äù workshop;
              </li>
              <li>
                <em>‚ÄúLikelihood-Free Frequentist Inference for Calorimetric Muon Energy Measurement in High-Energy Physics‚Äù</em> at the 
                ‚ÄúMachine Learning for the Physical Sciences‚Äù workshop.
              </li>
            </ul>
          </li>
          <br>
          <li>
            <b>08/2022</b> - Gave a talk on my recent work in Likelihood-Free Inference at JSM 2022 in Washington, D.C. My presentation was part of a topic-contributed session on 
            ‚ÄúInnovative Statistical Methods for Foundational Astrophysical Sciences‚Äù.
          </li>
          <br>
          <li>
            <b>06/2022</b> - Excited to start as a Summer 2022 Machine Learning Scientist Intern at <a href="https://www.amazon.science/">AWS - AI LABS</a> in Berlin, Germany. 
            I will join the Labor Forecasting team to work on distribution shift in time series settings.
          </li>
          <br>
          <li>
            <b>05/2022</b> - Looking forward to present our recent work at the <a href="https://indico.cern.ch/event/1078970/">5<sup>th</sup> Inter-experiment Machine Learning Workshop</a> at CERN, Geneva. I will talk about how to obtain valid 
            confidence regions from prediction algorithms or posterior estimators within a simulation-based inference setting, with an application to calorimetric muon energy measurements.
            [
            <a href="https://indico.cern.ch/event/1078970/contributions/4833280/attachments/2443529/4186711/talk.pdf">slides</a> 
            / 
            <a href="https://indico.cern.ch/event/1078970/contributions/4833280/attachments/2443529/4188128/GMT20220513-120234_Recording_1920x1080.mp4">recording</a>
            ]
          </li>
          -->
        </ul>
  
      </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications and Preprints</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:top">
              <div class="one">
                <img src='images/rna_seq.png' width="180">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Classification under Nuisance Parameters and Generalized Label Shift in Likelihood-Free Inference</papertitle>
              <p></p>
              <strong>Luca Masserano</strong>,
              <a href="https://www.cmu.edu/dietrich/statistics-datascience/people/phd/alex-shen.html">Alex Shen</a>, 
              <a href="https://userswww.pd.infn.it/~dorigo/">Tommaso Dorigo</a>, 
              <a href="https://userswww.pd.infn.it/~mdoro/">Michele Doro</a>, 
							<a href="http://www.rizbicki.ufscar.br/">Rafael Izbicki</a>,
              <a href="https://www.stat.cmu.edu/~annlee/">Ann B. Lee</a>
              <br>
              <em>ICML</em>, 2024
              <br>
              [
              <a href="https://arxiv.org/abs/2402.05330">paper</a>
              /
              <a href="https://github.com/lee-group-cmu/lf2i">code</a>
              ]
              <br>
              <p>
                We propose a new method for robust uncertainty quantification that casts classification as a hypothesis testing problem under nuisance parameters. The key idea is to estimate
                the classifier‚Äôs ROC across the entire nuisance parameter space, which allows us to devise cutoffs that are invariant under generalized label shifts. Our 
                method effectively endows a pre-trained classifier with domain adaptation capabilities and returns valid prediction sets while maintaining high power.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/e2e_pipeline.png' width="140">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>End-to-end Learning of Mixed-Integer Programs via Stochastic Perturbations</papertitle>
              <p></p>
              <strong>Luca Masserano</strong>,
              <a href="https://scholar.google.com/citations?user=i3UOvhYAAAAJ&hl=en">Syama Sundar Rangapuram</a>, 
							<a href="https://lostella.github.io/">Lorenzo Stella</a>,
              <a href="https://scholar.google.com.hk/citations?user=_JU-vN8AAAAJ&hl=en">Konstantinos Benidis</a>,
              <a href="https://urosolia.github.io/">Ugo Rosolia</a>,
              <a href="https://scholar.google.com/citations?user=19k2WQEAAAAJ&hl=de">Michael Bohlke-Schneider</a>
              <br>
              <em>In preparation</em>, 2023
              <br>
              <p>
                We developed theory and methodology to embed arbitrary mixed-integer programs as differentiable blocks of deep learning pipelines via stochastic perturbations of the optimization inputs. 
                We also proposed to exploit inluence functions to do sensitivity analysis on the combinatorial solvers and drive perturbations in the optimal direction.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/waldo.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Simulation-Based Inference with WALDO: Confidence Regions by Leveraging Prediction Algorithms and
                Posterior Estimators for Inverse Problems</papertitle>
              <p></p>
              <strong>Luca Masserano</strong>,
              <a href="https://userswww.pd.infn.it/~dorigo/">Tommaso Dorigo</a>, 
							<a href="http://www.rizbicki.ufscar.br/">Rafael Izbicki</a>,
              <a href="https://www.stat.cmu.edu/~mkuusela/">Mikael Kuusela</a>,
              <a href="https://www.stat.cmu.edu/~annlee/">Ann B. Lee</a>
              <br>
              <em>AISTATS</em>, 2023
              <br>
              <strong>Winner of the 2023 American Statistical Association SPES Student Paper Competition</strong>
              <br>
              [
              <a href="https://arxiv.org/abs/2205.15680">paper</a>
              /
              <a href="https://github.com/lee-group-cmu/lf2i">code</a>
              /
              <a href="https://lee-group-cmu.github.io/lf2i">docs</a>
              ]
              <p></p>
              <p>
                WALDO allows to exploit arbitrary prediction algorithms and posterior estimators to construct reliable confidence sets for parameters of interest in 
                simulation-based inference, i.e. when the likelihood is intractable but we can sample from it. Confidence sets from WALDO are guaranteed to be valid at the 
                correct coverage level without being overly conservative. In addition, one can still exploit prior knowledge to achieve tighter constraints.
              </p>
            </td>
          </tr>

          <tr>
            <tr onmouseout="ada_stop()" onmouseover="ada_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='ada_image'>
                    <img src='images/ada_sampling2.png' width="160"></div>
                  <img src='images/ada_sampling1.png' width="160">
                </div>
                <script type="text/javascript">
                  function ada_start() {
                    document.getElementById('ada_image').style.opacity = "1";
                  }
  
                  function ada_stop() {
                    document.getElementById('ada_image').style.opacity = "0";
                  }
                  ada_stop()
                </script>
              </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Adaptive Sampling for Probabilistic Forecasting under Distribution Shift</papertitle>
              <p></p>
              <strong>Luca Masserano</strong>,
              <a href="https://scholar.google.com/citations?user=i3UOvhYAAAAJ&hl=en">Syama Sundar Rangapuram</a>, 
							<a href="https://scholar.google.de/citations?user=4LLHaikAAAAJ&hl=en">Shubham Kapoor</a>,
              <a href="https://scholar.google.com/citations?user=D3yw4goAAAAJ&hl=de">Rajbir Singh Nirwan</a>,
              <a href="https://youngsuk0723.github.io/">Youngsuk Park</a>,
              <a href="https://scholar.google.com/citations?user=19k2WQEAAAAJ&hl=de">Michael Bohlke-Schneider</a>
              <br>
              <em>NeurIPS Distribution Shifts Workshop (DistShift)</em>, 2022
              <br>
              [
              <a href="https://www.amazon.science/publications/adaptive-sampling-for-probabilistic-forecasting-under-distribution-shift">paper</a>
              ]
              <p></p>
              <p>
                We present an adaptive sampling strategy that selects the part of the time series history that is relevant for forecasting. We achieve this by learning a discrete distribution over relevant time steps by Bayesian optimization. 
                We instantiate this idea with a two-step method that is pre-trained with uniform sampling and then training a lightweight adaptive architecture with adaptive sampling.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/lf2i.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Likelihood-Free Frequentist Inference: Confidence Sets with Correct Conditional Coverage</papertitle>
              <p></p>
              <a href="https://www.niccolodalmasso.com/">Niccol√≤ Dalmasso<sup>*</sup></a>, 
              <strong>Luca Masserano</strong><sup>*</sup>,
              <a href="https://davidzhao.netlify.app/">David Zhao</a>,
							<a href="http://www.rizbicki.ufscar.br/">Rafael Izbicki</a>,
              <a href="https://www.stat.cmu.edu/~annlee/">Ann B. Lee</a>
              <br>
              <em>Under review</em>
              <br>
              [
              <a href="https://arxiv.org/abs/2107.03920">paper</a>
              /
              <a href="https://github.com/lee-group-cmu/lf2i">code</a>
              /
              <a href="https://lee-group-cmu.github.io/lf2i">docs</a>
              /
              <a href="data/LF2I_supplementary_material.pdf">supplementary material</a>
              ], <sup>*</sup><em>equal contribution</em>
              <p></p>
              <p>
                In this work, we propose a unified and modular inference framework that bridges classical statistics and modern machine learning in SBI/LFI providing <i>(i)</i> a 
                practical approach to the Neyman construction of confidence sets with frequentist finite-sample coverage for any value of the unknown parameters; and <i>(ii)</i> 
                interpretable diagnostics that estimate the empirical coverage across the entire parameter space.
              </p>
            </td>
          </tr>
		
        </tbody></table>

				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Experience</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/aws.jpeg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Amazon - AWS AI LABS</papertitle>
              <br>
              <i>Machine Learning Scientist Intern</i> 
              <br>
              <b>Manager:</b> <a href="https://dcmaddix.github.io/">Danielle Robinson</a>, <b>Mentors:</b> <a href="https://abdulfatir.com/">Abdul F. Ansari</a>, <a href="https://boranhan.github.io/">Boran Han</a>, <a href="https://scholar.google.com/citations?user=i3UOvhYAAAAJ&hl=en">Syama Rangapuram</a>
              <br>
              June-August 2024, Santa Clara (California)
              <p></p>
              <p>
                I am working on developing new Foundation Models for time series, specifically with an eye on using tokenizers based on Wavelets.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/aws.jpeg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Amazon - AWS AI LABS</papertitle>
              <br>
              <i>Machine Learning Scientist Intern</i> 
              <br>
              <b>Manager:</b> <a href="https://lostella.github.io/">Lorenzo Stella</a>, <b>Mentor:</b> <a href="https://scholar.google.com/citations?user=i3UOvhYAAAAJ&hl=en">Syama Sundar Rangapuram</a>
              <br>
              June-August 2023, Berlin (Germany)
              <p></p>
              <p>
                Developed theory and methodology to embed arbitrary mixed-integer programs as differentiable blocks of deep learning pipelines via stochastic perturbations of the optimization inputs. Proposed to exploit 
                inluence functions to do sensitivity analysis on the combinatorial solvers and drive perturbations in the optimal direction.
              </p>
            </td>
          </tr>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/aws.jpeg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Amazon - AWS AI LABS</papertitle>
              <br>
              <i>Machine Learning Scientist Intern</i> 
              <br>
              <b>Manager:</b> <a href="https://scholar.google.com/citations?user=19k2WQEAAAAJ&hl=de">Michael Bohlke-Schneider</a>, <b>Mentor:</b> <a href="https://scholar.google.com/citations?user=i3UOvhYAAAAJ&hl=en">Syama Sundar Rangapuram</a>
              <br>
              June-August 2022, Berlin (Germany)
              <p></p>
              <p>
                Built a time series forecasting method that is robust under distribution shifts. I proposed a novel adaptive sampling approach and delivered an implementation that <i>(i)</i> avoids noisy data 
                regions, <i>(ii)</i> focuses on relevant shifted region in the past, and <i>(iii)</i> has also promising first results with real-world datasets with known distribution shifts. 
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/blackrock.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>BlackRock - Financial Modeling Group (FMG)</papertitle>
              <br>
              <i>Quantitative Analyst Intern</i> 
              <br>
              <b>Manager:</b> Joo Chew Ang
              <br>
              July-September 2019, London (UK)
              <p></p>
              <p>
                Designed and developed a new research platform that allows to inspect the downstream effect of any modification in a suite of equity risk models. This platform streamlined 
                the research process by reducing time between idea generation and implementation. I also worked with software engineers to refine compliance of production code with quantitative models' logic.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/smartfab.webp' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>SmartFAB</papertitle>
              <br>
              <i>Data Scientist Intern</i> 
              <br>
              <b>Mentors:</b> <a href="https://scholar.google.com/citations?user=DYUloYkAAAAJ&hl=en">Carlo Baldassi</a>, <a href="https://scholar.google.com/citations?user=1IPn2HgAAAAJ&hl=en">Carlo Lucibello</a>
              <br>
              March-May 2019, Milan (Italy)
              <p></p>
              <p>
                Exploited various statistical models to improve real-time detection of damaged integrated circuits produced in a semiconductor plant in southern Italy.
              </p>
            </td>
          </tr>
					
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
                  <a href="https://github.com/jonbarron/jonbarron_website"><strong>Created from Jonathan T. Barron's template</strong></a>
                  </font>
              </p>
            </td>
          </tr>
        </table>

      </td>
    </tr>
  </table>
</body>

</html>
